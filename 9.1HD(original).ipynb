{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4drr-I8z7na"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_mP-YAm3z7nb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "import glob\n",
        "import math\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIUsqir9z7nc"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P4aXbIAtz7nc"
      },
      "outputs": [],
      "source": [
        "train_set = pd.read_csv(\"data/trainingData.csv\")\n",
        "test_set = pd.read_csv(\"data/validationData.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GagdnIH3z7nc"
      },
      "source": [
        "# Evaluate Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LqLkY8FCz7nn",
        "outputId": "3327850d-3ad2-4ce3-89ee-9ce4a33c6352"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(pd.isnull(train_set).values.any())\n",
        "print(pd.isnull(test_set).values.any())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exgwoXLZz7nn"
      },
      "source": [
        "# Preprocess Data and Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7NRU_8Cz7nn"
      },
      "source": [
        "Training/validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PyV66ZFoz7no"
      },
      "outputs": [],
      "source": [
        "train_set.iloc[:, 0:520].min().min()\n",
        "train_set_P = train_set.copy()\n",
        "train_set_P.iloc[:, 0:520] = np.where(train_set_P.iloc[:, 0:520] <= 0, train_set_P.iloc[:, 0:520] + 105, train_set_P.iloc[:, 0:520] - 100) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NQBWoFFnz7no",
        "outputId": "6ec80bb9-9a21-498b-9993-62afc4d81660"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1997"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined = pd.concat([train_set_P, test_set])\n",
        "combined = combined.assign(UNIQUELOCATION = (combined['LONGITUDE'].astype(str) + '_' + combined['LATITUDE'].astype(str) + '_' + combined['FLOOR'].astype(str) + '_' + combined['BUILDINGID'].astype(str)).astype('category').cat.codes)\n",
        "len(combined[\"UNIQUELOCATION\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SgU4afnnz7no"
      },
      "outputs": [],
      "source": [
        "train_set_PU = combined.iloc[0:19937, :]\n",
        "test_set_U = combined.iloc[19937:21048, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xNWKTNmyz7np"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-2bde1dc609ec>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_set_PU[\"UNIQUELOCATION\"] = train_set_PU[\"UNIQUELOCATION\"].astype(\"category\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "WAP001                 int64\n",
              "WAP002                 int64\n",
              "WAP003                 int64\n",
              "WAP004                 int64\n",
              "WAP005                 int64\n",
              "                      ...   \n",
              "RELATIVEPOSITION       int64\n",
              "USERID                 int64\n",
              "PHONEID                int64\n",
              "TIMESTAMP              int64\n",
              "UNIQUELOCATION      category\n",
              "Length: 530, dtype: object"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set_PU[\"UNIQUELOCATION\"] = train_set_PU[\"UNIQUELOCATION\"].astype(\"category\")\n",
        "train_set_PU.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "i8DFNArWz7np"
      },
      "outputs": [],
      "source": [
        "X_train = train_set_PU.iloc[:, 0:520]\n",
        "y_train = train_set_PU.iloc[:, 520:530]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vhMVT75z7nq"
      },
      "source": [
        "Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7zzBKH0yz7nq"
      },
      "outputs": [],
      "source": [
        "test_set_PU = test_set_U.copy()\n",
        "test_set_PU.iloc[:, 0:520] = np.where(test_set_PU.iloc[:, 0:520] <= 0, test_set_PU.iloc[:, 0:520] + 105, test_set_PU.iloc[:, 0:520] - 100) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "e0QIpSDzz7nr",
        "outputId": "27971b93-6cd3-4e66-adca-a29f70c6b981"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "WAP001                 int64\n",
              "WAP002                 int64\n",
              "WAP003                 int64\n",
              "WAP004                 int64\n",
              "WAP005                 int64\n",
              "                      ...   \n",
              "RELATIVEPOSITION       int64\n",
              "USERID                 int64\n",
              "PHONEID                int64\n",
              "TIMESTAMP              int64\n",
              "UNIQUELOCATION      category\n",
              "Length: 530, dtype: object"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_set_PU[\"UNIQUELOCATION\"] = test_set_PU[\"UNIQUELOCATION\"].astype(\"category\")\n",
        "test_set_PU.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BOD-yG9cz7nr"
      },
      "outputs": [],
      "source": [
        "X_test = test_set_PU.iloc[:, 0:520]\n",
        "y_test = test_set_PU.iloc[:, 520:530]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "npUw-KSXz7nr"
      },
      "outputs": [],
      "source": [
        "ref_table = pd.concat([y_train.iloc[:, [0,1,2,3,9]], y_test.iloc[:, [0,1,2,3,9]]])\n",
        "ref_table = ref_table.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "F0Tfj2JWz7nr"
      },
      "outputs": [],
      "source": [
        "def save_data(dataframe, filename):\n",
        "    file_present = glob.glob(filename)\n",
        "    if not file_present:\n",
        "        dataframe.to_csv(filename)\n",
        "    else:\n",
        "        print('WARNING: This file already exists.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qg4wKgVCz7nt"
      },
      "outputs": [],
      "source": [
        "del train_set, train_set_P, train_set_PU, test_set, test_set_U, test_set_PU, combined"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1o-spBNz7nt"
      },
      "source": [
        "# Train Model(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCSCBH3hz7nt"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aH5g9sAYz7nt"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state = 0)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "hyperparameters = {'criterion': ['gini'], \n",
        "                'max_depth': [None], \n",
        "                'max_features': ['sqrt'],\n",
        "                'n_estimators': [60]}\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import make_scorer\n",
        "scoring = {'accuracy': 'accuracy',\n",
        "            'kappa': make_scorer(cohen_kappa_score)}\n",
        "\n",
        "grid = GridSearchCV(estimator = classifier,\n",
        "                    param_grid = hyperparameters,\n",
        "                    scoring = scoring,\n",
        "                    cv = 2,\n",
        "                    refit = 'accuracy',\n",
        "                    return_train_score = True,\n",
        "                    n_jobs = -1) \n",
        "\n",
        "tic = time.time()\n",
        "grid_result = grid.fit(X_train, y_train.iloc[:, 9].squeeze())\n",
        "toc = time.time()\n",
        "run_time = (toc - tic)/60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JrpPiZrCz7nu"
      },
      "outputs": [],
      "source": [
        "cv_results_ = pd.DataFrame.from_dict(grid_result.cv_results_) \n",
        "cv_results_.insert(loc = 0, column = 'Model', \n",
        "                   value = ['RandomForestClassifier']*cv_results_.shape[0])\n",
        "cv_results_.insert(loc = 28, column = 'mean train - cross_val accuracy',  # loc = 60 if you use cv=10\n",
        "                   value = cv_results_['mean_train_accuracy'] - cv_results_['mean_test_accuracy'])\n",
        "cv_results_.insert(loc = 29, column = 'mean train - cross_val kappa',   # loc = 61 if you use cv=10\n",
        "                   value = cv_results_['mean_train_kappa'] - cv_results_['mean_test_kappa'])\n",
        "with open('tuning_rf.csv', 'a') as f:\n",
        "    cv_results_.to_csv(f, header = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1xafEf7iz7nv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'criterion': 'gini',\n",
              " 'max_depth': None,\n",
              " 'max_features': 'sqrt',\n",
              " 'n_estimators': 60}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_result.best_estimator_\n",
        "grid_result.best_score_\n",
        "grid_result.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZYQw3K-4z7nw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0054005400540054005"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = grid_result.predict(X_test)\n",
        "np.mean(y_pred == y_test.iloc[:, 9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XUpb6oGoz7nx"
      },
      "outputs": [],
      "source": [
        "y_test_pos = y_test.iloc[:, 0:2].values \n",
        "y_test_floor = y_test.iloc[:, 2].values\n",
        "y_test_building = y_test.iloc[:, 3].values\n",
        "\n",
        "dict_loc = {}\n",
        "m_total = ref_table.shape[0]\n",
        "for i in range(m_total):\n",
        "    key = int(ref_table.iloc[i]['UNIQUELOCATION'])\n",
        "    value = ref_table.iloc[i, 0:4].values\n",
        "    dict_loc[key] = value\n",
        "\n",
        "y_pred_pos = np.asarray([dict_loc[i] for i in y_pred])[:, 0:2] \n",
        "y_pred_floor = np.asarray([dict_loc[i] for i in y_pred])[:, 2]\n",
        "y_pred_building = np.asarray([dict_loc[i] for i in y_pred])[:, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZWP4xapdz7nx"
      },
      "outputs": [],
      "source": [
        "def euclidean(y_test_pos, y_pred_pos):\n",
        "    m_test = y_test_pos.shape[0]\n",
        "    D_error = np.sum((y_test_pos - y_pred_pos)**2, axis = 1)**0.5\n",
        "    return D_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RBHJFjYIz7ny"
      },
      "outputs": [],
      "source": [
        "D_error = euclidean(y_test_pos, y_pred_pos)\n",
        "sorted_D_error = sorted(D_error)\n",
        "\n",
        "m_test = y_test.shape[0]\n",
        "mean_error = np.mean(D_error) \n",
        "percentile_25th = sorted_D_error[math.ceil(m_test*0.25) - 1] \n",
        "percentile_50th = sorted_D_error[math.ceil(m_test*0.50) - 1] \n",
        "percentile_75th = sorted_D_error[math.ceil(m_test*0.75) - 1] \n",
        "percentile_95th = sorted_D_error[math.ceil(m_test*0.95) - 1] \n",
        "percentile_100th = sorted_D_error[math.ceil(m_test*1.00) - 1] \n",
        "building_hitrate = np.mean(y_test_building == y_pred_building)\n",
        "floor_hitrate = np.mean(y_test_floor == y_pred_floor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8.578918235862663\n"
          ]
        }
      ],
      "source": [
        "mean_error = np.mean(D_error)\n",
        "print(mean_error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1>Decision Tree</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.09467534224192302\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "neural = DecisionTreeClassifier(random_state=0)\n",
        "scoring = {'accuracy': 'accuracy', 'kappa': make_scorer(cohen_kappa_score)}\n",
        "\n",
        "tic = time.time()\n",
        "neural.fit(X_train, y_train.iloc[:, 9].squeeze())\n",
        "toc = time.time()\n",
        "run_time = (toc - tic)/60\n",
        "print(run_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0027002700270027003"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = neural.predict(X_test)\n",
        "np.mean(y_pred == y_test.iloc[:, 9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_pos = y_test.iloc[:, 0:2].values\n",
        "y_test_floor = y_test.iloc[:, 2].values\n",
        "y_test_building = y_test.iloc[:, 3].values\n",
        "\n",
        "dict_loc = {}\n",
        "m_total = ref_table.shape[0]\n",
        "for i in range(m_total):\n",
        "    key = int(ref_table.iloc[i]['UNIQUELOCATION'])\n",
        "    value = ref_table.iloc[i, 0:4].values\n",
        "    dict_loc[key] = value\n",
        "\n",
        "y_pred_pos = np.asarray([dict_loc[i] for i in y_pred])[:, 0:2]\n",
        "y_pred_floor = np.asarray([dict_loc[i] for i in y_pred])[:, 2]\n",
        "y_pred_building = np.asarray([dict_loc[i] for i in y_pred])[:, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "D_error = euclidean(y_test_pos, y_pred_pos)\n",
        "sorted_D_error = sorted(D_error)\n",
        "\n",
        "m_test = y_test.shape[0]\n",
        "mean_error = np.mean(D_error) \n",
        "percentile_25th = sorted_D_error[math.ceil(m_test*0.25) - 1] \n",
        "percentile_50th = sorted_D_error[math.ceil(m_test*0.50) - 1] \n",
        "percentile_75th = sorted_D_error[math.ceil(m_test*0.75) - 1] \n",
        "percentile_95th = sorted_D_error[math.ceil(m_test*0.95) - 1] \n",
        "percentile_100th = sorted_D_error[math.ceil(m_test*1.00) - 1] \n",
        "building_hitrate = np.mean(y_test_building == y_pred_building)\n",
        "floor_hitrate = np.mean(y_test_floor == y_pred_floor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13.840359196110223\n"
          ]
        }
      ],
      "source": [
        "mean_error = np.mean(D_error)\n",
        "print(mean_error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1>kNN</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.00030085245768229164\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neural = KNeighborsClassifier(n_neighbors=5, weights=\"distance\")\n",
        "scoring = {'accuracy': 'accuracy', 'kappa': make_scorer(cohen_kappa_score)}\n",
        "\n",
        "tic = time.time()\n",
        "neural.fit(X_train, y_train.iloc[:, 9].squeeze())\n",
        "toc = time.time()\n",
        "run_time = (toc - tic)/60\n",
        "print(run_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0054005400540054005"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = neural.predict(X_test)\n",
        "np.mean(y_pred == y_test.iloc[:, 9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_pos = y_test.iloc[:, 0:2].values\n",
        "y_test_floor = y_test.iloc[:, 2].values\n",
        "y_test_building = y_test.iloc[:, 3].values\n",
        "\n",
        "dict_loc = {}\n",
        "m_total = ref_table.shape[0]\n",
        "for i in range(m_total):\n",
        "    key = int(ref_table.iloc[i]['UNIQUELOCATION'])\n",
        "    value = ref_table.iloc[i, 0:4].values\n",
        "    dict_loc[key] = value\n",
        "\n",
        "y_pred_pos = np.asarray([dict_loc[i] for i in y_pred])[:, 0:2]\n",
        "y_pred_floor = np.asarray([dict_loc[i] for i in y_pred])[:, 2]\n",
        "y_pred_building = np.asarray([dict_loc[i] for i in y_pred])[:, 3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "D_error = euclidean(y_test_pos, y_pred_pos)\n",
        "sorted_D_error = sorted(D_error)\n",
        "\n",
        "m_test = y_test.shape[0]\n",
        "mean_error = np.mean(D_error)\n",
        "percentile_25th = sorted_D_error[math.ceil(m_test*0.25) - 1]\n",
        "percentile_50th = sorted_D_error[math.ceil(m_test*0.50) - 1]\n",
        "percentile_75th = sorted_D_error[math.ceil(m_test*0.75) - 1]\n",
        "percentile_95th = sorted_D_error[math.ceil(m_test*0.95) - 1]\n",
        "percentile_100th = sorted_D_error[math.ceil(m_test*1.00) - 1]\n",
        "building_hitrate = np.mean(y_test_building == y_pred_building)\n",
        "floor_hitrate = np.mean(y_test_floor == y_pred_floor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9.95949930276953\n"
          ]
        }
      ],
      "source": [
        "mean_error = np.mean(D_error)\n",
        "print(mean_error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1>Gaussian NB</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.017563374837239583\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "neural = GaussianNB()\n",
        "scoring = {'accuracy': 'accuracy', 'kappa': make_scorer(cohen_kappa_score)}\n",
        "\n",
        "tic = time.time()\n",
        "neural.fit(X_train, y_train.iloc[:, 9].squeeze())\n",
        "toc = time.time()\n",
        "run_time = (toc - tic)/60\n",
        "print(run_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.004500450045004501"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = neural.predict(X_test)\n",
        "np.mean(y_pred == y_test.iloc[:, 9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_pos = y_test.iloc[:, 0:2].values\n",
        "y_test_floor = y_test.iloc[:, 2].values\n",
        "y_test_building = y_test.iloc[:, 3].values\n",
        "\n",
        "dict_loc = {}\n",
        "m_total = ref_table.shape[0]\n",
        "for i in range(m_total):\n",
        "    key = int(ref_table.iloc[i]['UNIQUELOCATION'])\n",
        "    value = ref_table.iloc[i, 0:4].values\n",
        "    dict_loc[key] = value\n",
        "\n",
        "y_pred_pos = np.asarray([dict_loc[i] for i in y_pred])[:, 0:2]\n",
        "y_pred_floor = np.asarray([dict_loc[i] for i in y_pred])[:, 2]\n",
        "y_pred_building = np.asarray([dict_loc[i] for i in y_pred])[:, 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "D_error = euclidean(y_test_pos, y_pred_pos)\n",
        "sorted_D_error = sorted(D_error)\n",
        "\n",
        "m_test = y_test.shape[0]\n",
        "mean_error = np.mean(D_error)\n",
        "percentile_25th = sorted_D_error[math.ceil(m_test*0.25) - 1]\n",
        "percentile_50th = sorted_D_error[math.ceil(m_test*0.50) - 1]\n",
        "percentile_75th = sorted_D_error[math.ceil(m_test*0.75) - 1]\n",
        "percentile_95th = sorted_D_error[math.ceil(m_test*0.95) - 1]\n",
        "percentile_100th = sorted_D_error[math.ceil(m_test*1.00) - 1]\n",
        "building_hitrate = np.mean(y_test_building == y_pred_building)\n",
        "floor_hitrate = np.mean(y_test_floor == y_pred_floor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13.064457035409692\n"
          ]
        }
      ],
      "source": [
        "mean_error = np.mean(D_error)\n",
        "print(mean_error)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "wifi_locationing_rf.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
